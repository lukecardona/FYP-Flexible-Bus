{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run classesDefinations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import gymnasium\n",
    "import numpy as np\n",
    "from gymnasium.spaces import Discrete, Dict, Box\n",
    "from gymnasium.wrappers import FlattenObservation #IMPORTANT USE IT TO FLATTEN OBS SPACE\n",
    "\n",
    "from pettingzoo import AECEnv\n",
    "from pettingzoo.utils import agent_selector, wrappers\n",
    "\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBEROFBUSES = 10\n",
    "CAPACITY = 5\n",
    "VEHILECORDSLAT = 35.8942679\n",
    "VEHILECORDSLOG = 14.5086503 #CORDS OF THE 15 VALLETTA BUS BAY\n",
    "\n",
    "dataFilePath = \"./Data/BusStopsMalta/export.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def divide_time_interval(n):\n",
    "    \"\"\"\n",
    "    Divides the time interval between 8:00 AM and Midnight into 'n' equal intervals.\n",
    "\n",
    "    Parameters:\n",
    "    n (int): Number of intervals to divide the time into.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of time intervals.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define start and end times\n",
    "    start_time = datetime.strptime(\"08:00 AM\", \"%I:%M %p\")\n",
    "    end_time = datetime.strptime(\"12:00 AM\", \"%I:%M %p\")\n",
    "\n",
    "    # Calculate total duration in seconds\n",
    "    total_duration = (end_time - start_time).seconds\n",
    "\n",
    "    # Calculate duration of each interval in seconds\n",
    "    interval_duration = total_duration / n\n",
    "\n",
    "    # Generate time intervals\n",
    "    intervals = []\n",
    "    for i in range(n):\n",
    "        interval_start = start_time + timedelta(seconds=i * interval_duration)\n",
    "        intervals.append(interval_start.time())\n",
    "\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle: id: 2125993963152, capacity: 5, currentPosition: lat: 35.8942679,long: 14.5086503, route: 0\n"
     ]
    }
   ],
   "source": [
    "class BusRoutingHandler():\n",
    "    def __init__(self, vehileAmount = 10, numberOfRequest = 50):\n",
    "        self.vehiles = self.initVehiles(vehileAmount)\n",
    "        self.requests = self.initRequests(numberOfRequest)\n",
    "    \n",
    "    def initVehiles(self, vehileAmount):\n",
    "        vehileList = []\n",
    "        for i in range(vehileAmount):\n",
    "            vechCords = Cords(VEHILECORDSLAT, VEHILECORDSLOG)\n",
    "            vehileList.append(Vehicle(CAPACITY, vechCords))\n",
    "        return vehileList\n",
    "\n",
    "    def initRequests(self, numberOfRequest):\n",
    "        timeIntervals = divide_time_interval(numberOfRequest)\n",
    "        f = open(dataFilePath, \"r\")\n",
    "        data = json.load(f)\n",
    "        elements = data[\"elements\"]\n",
    "        elementsLen = len(elements)\n",
    "        request = []\n",
    "        time = 0\n",
    "        for i in range(numberOfRequest):\n",
    "            #Get two random indexes from all the bus stops \n",
    "            r1 = random.randint(0, elementsLen-1)\n",
    "            r2 = random.randint(0, elementsLen-1)\n",
    "            while r1 == r2:\n",
    "                r2 = random.randint(0, elementsLen-1)\n",
    "            \n",
    "            #Get the coordinates of the two bus stops\n",
    "            lat1 = elements[r1][\"lat\"]\n",
    "            lon1 = elements[r1][\"lon\"]\n",
    "            lat2 = elements[r2][\"lat\"]\n",
    "            lon2 = elements[r2][\"lon\"]\n",
    "\n",
    "            #Create the request Cords\n",
    "            reqPickup = RequestCords(lat1, lon1, True)\n",
    "            reqDropoff = RequestCords(lat2, lon2, False)\n",
    "\n",
    "            #Create the request\n",
    "            time += 20\n",
    "            request.append(Request(random.randint(1,3), reqPickup, reqDropoff, timeIntervals[i]))\n",
    "        f.close()\n",
    "        return request\n",
    "\n",
    "    def getVehiles(self):\n",
    "        pass\n",
    "\n",
    "    def getRequests(self):\n",
    "        pass\n",
    "\n",
    "busRouting = BusRoutingHandler()\n",
    "print(busRouting.vehiles[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env(render_mode=None): #Petting Zoo Env\n",
    "    \"\"\"\n",
    "    The env function often wraps the environment in wrappers by default.\n",
    "    You can find full documentation for these methods\n",
    "    elsewhere in the developer documentation.\n",
    "    \"\"\"\n",
    "\n",
    "    internal_render_mode = render_mode if render_mode != \"ansi\" else \"human\"\n",
    "    env = raw_env(render_mode=internal_render_mode)\n",
    "\n",
    "    # This wrapper is only for environments which print results to the terminal\n",
    "    if render_mode == \"ansi\":\n",
    "        env = wrappers.CaptureStdoutWrapper(env)\n",
    "\n",
    "    # this wrapper helps error handling for discrete action spaces\n",
    "    env = wrappers.AssertOutOfBoundsWrapper(env)\n",
    "\n",
    "    # Provides a wide vareity of helpful user errors\n",
    "    # Strongly recommended\n",
    "    env = wrappers.OrderEnforcingWrapper(env)\n",
    "\n",
    "    return env\n",
    "\n",
    "class raw_env(AECEnv):\n",
    "    \"\"\"\n",
    "    The metadata holds environment constants. From gymnasium, we inherit the \"render_modes\",\n",
    "    metadata which specifies which modes can be put into the render() method.\n",
    "    At least human mode should be supported.\n",
    "    The \"name\" metadata allows the environment to be pretty printed.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\"], \"name\": \"Flexible_Bus\"}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        \"\"\"\n",
    "        The init method takes in environment arguments and\n",
    "         should define the following attributes:\n",
    "        - possible_agents\n",
    "        - render_mode\n",
    "\n",
    "        Note: as of v1.18.1, the action_spaces and observation_spaces attributes are deprecated.\n",
    "        Spaces should be defined in the action_space() and observation_space() methods.\n",
    "        If these methods are not overridden, spaces will be inferred from self.observation_spaces/action_spaces, raising a warning.\n",
    "\n",
    "        These attributes should not be changed after initialization.\n",
    "        \"\"\"\n",
    "\n",
    "        self.agents = [\"bus_\" + str(r) for r in range(NUMBEROFBUSES)]\n",
    "        self.possible_agents = self.agents[:]\n",
    "\n",
    "        #Set up action space and observation space\n",
    "        self._action_spaces = {\n",
    "            agent: Dict({\n",
    "                        \"accept_request\": Discrete(2),\n",
    "                        \"insert_request\": Discrete(CAPACITY), #Require Maskings\n",
    "                         }) for agent in self.possible_agents\n",
    "        }\n",
    "        \n",
    "        self._observation_spaces = {\n",
    "            agent: Dict({\n",
    "                \"observation\": Dict(\n",
    "                    { #Simple Defination containing the bus position cordinates and the bus capacity\n",
    "                    \"bus_position\": Box(low=0, high=90, shape=(2,), dtype=np.float32),\n",
    "                    \"bus_capacity\": Discrete(CAPACITY),\n",
    "                    \"request_position\":Box(low=0, high=90, shape=(2,), dtype=np.float32),\n",
    "                    }),\n",
    "                \"action_mask\": Dict(\n",
    "                    { #Action mask needed to not allow the bus to exceed capacity\n",
    "                    \"accept_request\": Box(low=0, high=1, shape=(2,), dtype=np.int8),\n",
    "                    \"insert_request\": Box(low=0, high=1, shape=(2,), dtype=np.int8),\n",
    "                    })\n",
    "            }) for agent in self.possible_agents\n",
    "        } \n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "    # Observation space defination\n",
    "    def observation_space(self, agent):\n",
    "        return self.observation_spaces[agent]\n",
    "\n",
    "    # Action space defination\n",
    "    def action_space(self, agent):\n",
    "        return self.action_spaces[agent]\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Renders the environment. In human mode, it can print to terminal, open\n",
    "        up a graphical window, or open up some other display that a human can see and understand.\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def observe(self, agent):\n",
    "        \"\"\"\n",
    "        Observe should return the observation of the specified agent. This function\n",
    "        should return a sane observation (though not necessarily the most up to date possible)\n",
    "        at any time after reset() is called.\n",
    "        \"\"\"\n",
    "\n",
    "        #Change CODE to reflect agents values\n",
    "        observation = {\n",
    "            \"bus_position\": np.zeros(2,dtype=np.float32), \n",
    "            \"bus_capacity\": 0,\n",
    "            \"request_position\": np.zeros(2,dtype=np.float32),\n",
    "        }\n",
    "\n",
    "        #Change CODE to reflect agents values\n",
    "        action_mask = {\n",
    "            \"accept_request\": np.zeros(2,np.int8),\n",
    "            \"insert_request\": np.zeros(5,np.int8)\n",
    "        }\n",
    "\n",
    "        return {\"observation\": observation, \"action_mask\": action_mask}\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close should release any graphical displays, subprocesses, network connections\n",
    "        or any other environment data which should not be kept around after the\n",
    "        user is no longer using the environment.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"\n",
    "        Reset needs to initialize the following attributes\n",
    "        - agents\n",
    "        - rewards\n",
    "        - _cumulative_rewards\n",
    "        - terminations\n",
    "        - truncations\n",
    "        - infos\n",
    "        - agent_selection\n",
    "        And must set up the environment so that render(), step(), and observe()\n",
    "        can be called without issues.\n",
    "        Here it sets up the state dictionary which is used by step() and the observations dictionary which is used by step() and observe()\n",
    "        \"\"\"\n",
    "        self.agents = self.possible_agents[:]\n",
    "        self.rewards = {agent: 0 for agent in self.agents}\n",
    "        self._cumulative_rewards = {agent: 0 for agent in self.agents}\n",
    "        self.terminations = {agent: False for agent in self.agents}\n",
    "        self.truncations = {agent: False for agent in self.agents}\n",
    "        self.infos = {agent: {} for agent in self.agents}\n",
    "\n",
    "        #Self.state missing?\n",
    "        \n",
    "        \"\"\"\n",
    "        Selects the first Bus\n",
    "        \"\"\"\n",
    "        self._agent_selector = agent_selector(self.agents)\n",
    "        self.agent_selection = self._agent_selector.next()\n",
    "\n",
    "    #Requries Definations\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        step(action) takes in an action for the current agent (specified by\n",
    "        agent_selection) and needs to update\n",
    "        - rewards\n",
    "        - _cumulative_rewards (accumulating the rewards)\n",
    "        - terminations\n",
    "        - truncations\n",
    "        - infos\n",
    "        - agent_selection (to the next agent)\n",
    "        And any internal state used by observe() or render()\n",
    "        \"\"\"\n",
    "        if (\n",
    "            self.terminations[self.agent_selection]\n",
    "            or self.truncations[self.agent_selection]\n",
    "        ):\n",
    "            # handles stepping an agent which is already dead\n",
    "            # accepts a None action for the one agent, and moves the agent_selection to\n",
    "            # the next dead agent,  or if there are no more dead agents, to the next live agent\n",
    "            self._was_dead_step(action)\n",
    "            return\n",
    "\n",
    "        agent = self.agent_selection\n",
    "\n",
    "        # the agent which stepped last had its _cumulative_rewards accounted for\n",
    "        # (because it was returned by last()), so the _cumulative_rewards for this\n",
    "        # agent should start again at 0\n",
    "        self._cumulative_rewards[agent] = 0\n",
    "\n",
    "        # stores action of current agent\n",
    "        self.state[self.agent_selection] = action\n",
    "\n",
    "        # collect reward if it is the last agent to act\n",
    "        if self._agent_selector.is_last():\n",
    "            # rewards for all agents are placed in the .rewards dictionary\n",
    "            self.rewards[self.agents[0]], self.rewards[self.agents[1]] = REWARD_MAP[\n",
    "                (self.state[self.agents[0]], self.state[self.agents[1]])\n",
    "            ]\n",
    "\n",
    "            self.num_moves += 1\n",
    "            # The truncations dictionary must be updated for all players.\n",
    "            self.truncations = {\n",
    "                agent: self.num_moves >= NUM_ITERS for agent in self.agents\n",
    "            }\n",
    "\n",
    "            # observe the current state\n",
    "            for i in self.agents:\n",
    "                self.observations[i] = self.state[\n",
    "                    self.agents[1 - self.agent_name_mapping[i]]\n",
    "                ]\n",
    "        else:\n",
    "            # necessary so that observe() returns a reasonable observation at all times.\n",
    "            self.state[self.agents[1 - self.agent_name_mapping[agent]]] = NONE\n",
    "            # no rewards are allocated until both players give an action\n",
    "            self._clear_rewards()\n",
    "\n",
    "        # selects the next agent.\n",
    "        self.agent_selection = self._agent_selector.next()\n",
    "        # Adds .rewards to ._cumulative_rewards\n",
    "        self._accumulate_rewards()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP-EVRPTW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
